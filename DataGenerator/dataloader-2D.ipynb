{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is the instruction of generating the datasets for the experiments in the main paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import time\n",
    "import torch\n",
    "torch.set_num_threads(1) \n",
    "torch.set_default_dtype(torch.float64)\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parameter import Parameter\n",
    "import sys\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() \n",
    "parent_path = os.path.abspath(os.path.join(path, os.pardir))\n",
    "sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load DataGene.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (200,31,1001,10) (200,31,1001) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fe409dd42308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_max\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_option\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata_option\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# unstable case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_option\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/GoogleDrive/My Drive/High School/Research/ML for PDEs/DataGenerator/DataGene2D.py\u001b[0m in \u001b[0;36mPlain\u001b[0;34m(self, dt)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mtemp_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mtemp_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_c\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_term\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtemp_exp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mU\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (200,31,1001,10) (200,31,1001) "
     ]
    }
   ],
   "source": [
    "from DataGenerator.DataGene2D import *\n",
    "n = 10\n",
    "x_max = np.pi\n",
    "x_min = 0.0\n",
    "num_x = 30\n",
    "T_max = 1000.0\n",
    "beta = 5000.0\n",
    "IC = 200\n",
    "generator = DataGene2D(device=device,n=n,x_max=x_max,x_min=x_min,num_x=num_x,T_max=T_max,beta=beta,IC=IC)\n",
    "\n",
    "# save data?\n",
    "save_data = 1\n",
    "\n",
    "# choose which case to run\n",
    "data_option = 0\n",
    "# 0 - stable\n",
    "# 1 - unstable\n",
    "# 2 - noise medium\n",
    "# 3 - forcing\n",
    "dt=1.0\n",
    "length = int(T_max/dt)\n",
    "if data_option == 0 or data_option ==1:\n",
    "    dataset, traindata, testdata = generator.Plain(dt)\n",
    "    # unstable case\n",
    "    if data_option == 1:\n",
    "        dt = 200 # larger delta t here\n",
    "        length = int(T_max/dt)\n",
    "        dt_list = [i for i in xrange(0,int(T_max+dt),int(dt))]\n",
    "        traindata = traindata[:,:,dt_list]\n",
    "        testdata = testdata[:,:,dt_list]\n",
    "    print(dataset.shape, traindata.shape, testdata.shape)\n",
    "if data_option == 2:\n",
    "    err_scale = 1e-4 # the level of noise \n",
    "    dataset, traindata, testdata = generator.Noise(dt,err_scale)\n",
    "    print(dataset.shape, traindata.shape, testdata.shape)\n",
    "if data_option == 3:\n",
    "    f_scale = 10.0\n",
    "    dataset, traindata, testdata = generator.Force(dt,f_scale)\n",
    "    print(dataset.shape, traindata.shape, testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data if necessary\n",
    "if save_data == 1:\n",
    "    \n",
    "    savedata = OrderedDict()\n",
    "    \n",
    "    if data_option == 0 or data_option == 1:\n",
    "        datafile = 'case%s_dt%.2e.tar' % (data_option,dt)\n",
    "    if data_option == 2:\n",
    "        datafile = 'case%s_err%.2e_dt%.2e.tar' \\\n",
    "        % (data_option,err_scale,dt)\n",
    "    if data_option == 3:\n",
    "        datafile = 'case%s_force%.2e_dt%.2e.tar' \\\n",
    "        % (data_option,f_scale,dt)\n",
    "    \n",
    "    savedata = {\n",
    "        'data_option': data_option,\n",
    "        'data': dataset,\n",
    "        'train': traindata,\n",
    "        'test': testdata,\n",
    "    }\n",
    "    \n",
    "    torch.save(savedata,datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata[:,30,:]=0.0 \n",
    "testdata[:,30,:]=0.0\n",
    "traindata = traindata+1.0\n",
    "testdata = testdata+1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generator.DataForTrain(traindata)\n",
    "print x_train.shape, y_train.shape\n",
    "print x_train[150:].shape,y_train[:-150].shape\n",
    "print torch.sum(torch.abs(x_train[150:] - y_train[:-150])).data.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one step ahead prediction\n",
    "x_one, y_one = generator.DataForTest(testdata,1)\n",
    "\n",
    "# multi steps ahead prediction\n",
    "if data_option == 1:\n",
    "    multi_step = 3\n",
    "else:\n",
    "    multi_step = 10\n",
    "    \n",
    "x_mul, y_mul = generator.DataForTest(testdata,10)\n",
    "\n",
    "# sequential prediction (1000-step prediction)\n",
    "x_sq, y_sq = generator.DataForTest(testdata,length)\n",
    "\n",
    "y_one = y_one-1.0\n",
    "y_mul = y_mul-1.0\n",
    "y_sq= y_sq-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
